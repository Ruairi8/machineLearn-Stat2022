{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Jupyter Notebook Covering Exercises From Topic One Of The Machine Learning Module (Data Analytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>Q: Calculate the minimum number of cups of tea required to ensure the probability of randomly selecting the correct cups is less than or equal to 1%.<i/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has been adapted from Machine Learning & Statistics lecture. \n",
    "# The eight cups.\n",
    "cups = list(range(8))\n",
    "cups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(8*7*6*5)/(4*3*2*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "poss = list(itertools.combinations(cups, 4))\n",
    "poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.comb(8, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This outputs a 1.4% chance of selecting the correct cups.\n",
    "1/(math.comb(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs about half of a percent.\n",
    "1/(math.comb(10, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 cups of tea gives under one percent whereas 8 outputs over one percent; so the answer is 9 cups of tea. \n",
    "1/(math.comb(9, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/(math.comb(8, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>Q: How many would be required if you were to let the taster get one cup wrong while maintaining the 1% threshold?<i/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theres is roughly a 20% chance of guessing at least 3 cups correct.\n",
    "import math\n",
    "1/(math.comb(7, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "cups = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "poss = list(itertools.combinations(cups, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "# Pick a random correct answer from the list of 70 to simulate the experiment.\n",
    "milkfirst = set(random.choice(poss))\n",
    "\n",
    "# Count the overlap between the correct answer, and each of the 70 possiblities.\n",
    "counts = [len(milkfirst & set(i)) for i in itertools.combinations(cups, 3)]\n",
    "\n",
    "# Creat the plot.\n",
    "sns.countplot(x=counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>Q: Use scipy's version of Fisher's exact test to simulate the Lady Tasting Tea problem.<i/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "oddsratio, pvalue = fisher_exact([[4, 0], [0, 4]])\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'oddsratio' outputted from Fisher's exact test usually works on nominal variables with exactly two levels or categories. Nominal variables are usually qualitative, that is can't be assigned a numerical value but they can also be coded with numerical values, but the order is arbitary. The oddsratio compares the of positive occurances with the number of negatives occurances.<br>\n",
    "<br> Formula: oddsratio, OR = $(a / c)$ / $(b / d)$ <br>\n",
    "<br> An oddsratio of less than one means negative occurances were more common than positive occurances. An oddsratio equal to one means there is no relation between the variables in question. An oddsratio greater than one means positive cases were more common that negative cases. For example, an oddsration greater than one would mean a higher proportion of the results were as expected than the contrary. \n",
    "The 'p-value', the probability value, can be used to determine if you are rejecting the Null Hypothesis. It tells you how often you would expect to see a statistic from a test as or more extreme than the one calculated during your test if the Null Hypothesis of that test was true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "oddsratio, pvalue = fisher_exact([[3, 1], [1, 3]])\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As expected, the probability of her getting all correct is the same as getting all wrong:\n",
    "from scipy.stats import fisher_exact\n",
    "oddsratio, pvalue = fisher_exact([[0, 4], [4, 0]])\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "oddsratio, pvalue = fisher_exact([[2, 2], [2, 2]])\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import hypergeom\n",
    "table = np.array([[4, 0], [0, 4]])\n",
    "M = table.sum()\n",
    "n = table[0].sum()\n",
    "N = table[:, 0].sum()\n",
    "start, end = hypergeom.support(M, n, N)\n",
    "hypergeom.pmf(np.arange(start, end+1), M, n, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least 3 out of 4 correct guesses has a probability of 24%, which is greater than 5%. The only time the Null Hypothesis could be rejected was when she correctly guessed all 4 (0.014 = 1.4% which is < 5%).\n",
    "0.014 = 1/70, 0.2286 = 16/70. Adding these we get 17/70 = 0.24286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>Exercise: Take the code from the Examples section of the scipy stats documentation for independent samples t-tests, add it to your own notebook and add explain how it works using MarkDown cells and code comments. Improve it in any way you think it could be improved</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the relevant scipy and numpy packages. Initializing a Random Generator, and setting it to the variable rng. It is similar to the RandomState method but utilizes a BitGenerator to generate the random bits. The default is PCG64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test two samples with identical means. 'loc' specifies the mean. 'scale' specifies the standard deviation. 'random_state' is using an instance of the 'rng' Generator. 'norm' is an instance of the 'rv_continuous' class and inherits the rvs (random variates) method, which returns a random sample with probability equal to the distribution. The 'size' argument specifies the number of elements in the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs1 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)\n",
    "rvs2 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)\n",
    "# 'ttest_ind' calculates the T-test for the means of the 2 independent samples:\n",
    "stats.ttest_ind(rvs1, rvs2)\n",
    "#The resulting statistic and pvalue after the code is run:\n",
    "Ttest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952038870015)\n",
    "# 'equal_var' set to false performs Welchs T-test which doesn't assume theres an equal population variance:\n",
    "stats.ttest_ind(rvs1, rvs2, equal_var=False)\n",
    "Ttest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952553131064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.046790473889224, pvalue=0.29544967795371085)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs1 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)\n",
    "rvs2 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)\n",
    "# 'ttest_ind' calculates the T-test for the means of the 2 independent samples:\n",
    "stats.ttest_ind(rvs1, rvs2)\n",
    "#print(stats.ttest_ind(rvs1, rvs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.046790473889224, pvalue=0.29544968924486675)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'equal_var' set to false performs Welchs T-test which doesn't assume theres an equal population variance:\n",
    "stats.ttest_ind(rvs1, rvs2, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ttest_ind underestimates p for unequal variances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.9522246837817311, pvalue=0.34121360253963573)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs3 = stats.norm.rvs(loc=5, scale=20, size=500, random_state=rng)\n",
    "stats.ttest_ind(rvs1, rvs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.9522246837817311, pvalue=0.3413056233865962)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(rvs1, rvs3, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When n1 != n2, the equal variance t-statistic is no longer equal to the unequal variance t-statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.5475477310467716, pvalue=0.12226025292569571)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs4 = stats.norm.rvs(loc=5, scale=20, size=100, random_state=rng)\n",
    "stats.ttest_ind(rvs1, rvs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.063641616617173, pvalue=0.28979469954694376)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(rvs1, rvs4, equal_var=False)\n",
    "# A different t-statistic and pvalue due to no longer assuming the variance of the samples are equal, which they aren't:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-test with different means, variance, and n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.7456437577502664, pvalue=0.006220871068802192)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs5 = stats.norm.rvs(loc=8, scale=20, size=100, random_state=rng)\n",
    "stats.ttest_ind(rvs1, rvs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.8635862697296877, pvalue=0.06503065830368213)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(rvs1, rvs5, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing a permutation test, more permutations typically yields more accurate results. The 't distribution' is a probability distribution similar in shape to the bell curve of a 'normal distribution' but contains heavier tails. If no permutations parameter included, the function test uses the 't distribution'. This time a value is given for the permutations parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.7456437577502664, pvalue=0.005497251374312844)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a np.random.Generator to ensure reproducibility:\n",
    "stats.ttest_ind(rvs1, rvs5, permutations=2000, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.7456437577502664, pvalue=0.005499450054994501)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(rvs1, rvs5, permutations=10000,\n",
    "                random_state=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take these two samples, one of which has an extreme tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (56, 128.6, 12, 123.8, 64.34, 78, 763.3)\n",
    "b = (1.1, 2.9, 4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the trim keyword to perform a trimmed (Yuen) t-test. For example, using 20% trimming, trim=.2, the test will reduce the impact of one (np.floor(trim * len(a))) element from each tail of sample a. It will have no effect on sample b because (np.floor(trim * len(b)) is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrating the above statement:\n",
    "np.floor(0.2 * len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(0.2 * len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.4463884028073513, pvalue=0.01369338726499547)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(a, b, trim=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.832256715395378, pvalue=0.04723681941400341)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(a, b, trim=.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
